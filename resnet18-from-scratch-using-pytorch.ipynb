{"cells":[{"cell_type":"markdown","metadata":{},"source":["    In this notebook we'll use Pytorch to implement ResNet18 from scratch.\n","    We will also create a custom dataset class with augmentation\n","    \n","    Source article:\n","    https://arxiv.org/pdf/1512.03385.pdf"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-12-03T20:42:32.438373Z","iopub.status.busy":"2022-12-03T20:42:32.438076Z","iopub.status.idle":"2022-12-03T20:42:34.902994Z","shell.execute_reply":"2022-12-03T20:42:34.902022Z","shell.execute_reply.started":"2022-12-03T20:42:32.438306Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x7f36803b59d0>"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import time\n","import copy\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader, ConcatDataset\n","\n","torch.manual_seed(17)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train = pd.read_csv(\"../input/digit-recognizer/train.csv\",dtype = np.float32)\n","test = pd.read_csv(\"../input/digit-recognizer/test.csv\",dtype = np.float32)\n","submission = pd.read_csv(\"../input/digit-recognizer/sample_submission.csv\")\n","print(\"Train set shape:\", train.shape)\n","print(\"Test set shape:\", test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["#### Visualise label distribution"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["label_dist = dict(train.label.value_counts())\n","number = label_dist.keys()\n","count = label_dist.values() \n","   \n","fig = plt.figure(figsize = (8, 5)) \n","   \n","plt.bar(number, count, width = 0.5) \n","  \n","plt.xlabel(\"Label\") \n","plt.ylabel(\"No. of samples\") \n","plt.title(\"Distribution of labels\") \n","plt.show() "]},{"cell_type":"markdown","metadata":{},"source":["#### Visualize one of the images in the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.imshow(train.iloc[0, 1:].values.reshape(28,28))\n","plt.axis(\"off\")\n","plt.title(str(train.iloc[0, 0]))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Data preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#numpy.ndarray\n","labels = train.label.values\n","data = train.iloc[:, 1:].values / 255 # Normalization"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#torch.Tensor\n","labels = torch.from_numpy(labels).type(torch.LongTensor)\n","data = torch.from_numpy(data).view(data.shape[0], 1, 28, 28)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#split the data\n","train_data, val_data, train_labels, val_labels = train_test_split(data, labels, test_size = 0.2, random_state = 42) "]},{"cell_type":"markdown","metadata":{},"source":["#### TensorDataset class does not support transformations by default. We need to create a custom dataset class to add augmentations and use the data in DataLoaders"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class CustomTensorDataset(Dataset):\n","\n","    def __init__(self, data, labels=None, transform=None):      \n","        self.data = data\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __getitem__(self, index):       \n","        x = self.data[index]\n","        \n","        if self.transform is not None:\n","            x = self.transform(x)\n","        if self.labels is not None:\n","            y = self.labels[index]\n","            return x, y\n","        else:\n","            return x\n","\n","    def __len__(self):    \n","        return self.data.size(0)"]},{"cell_type":"markdown","metadata":{},"source":["#### As we work with tensors, we first need to transform our data to images, apply transformations and transform it back to tensors"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.RandomAffine(degrees=20, scale=(1.1, 1.1)),\n","    transforms.RandomCrop((28, 28), padding=2, pad_if_needed=True, fill=0, padding_mode='constant'),\n","    transforms.ToTensor()\n","])"]},{"cell_type":"markdown","metadata":{},"source":["#### Visualise data with and without augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sample = CustomTensorDataset(train_data[:3], train_labels[:3])\n","sample_aug = CustomTensorDataset(train_data[:3], train_labels[:3], transform=transform)\n","\n","fig, axs = plt.subplots(2, 3)\n","\n","for idx, item in enumerate(zip(sample, sample_aug)):\n","    \n","    im = item[0][0].squeeze().numpy()\n","    im_aug = item[1][0].squeeze().numpy()\n","\n","    axs[0, idx].imshow(im)\n","    axs[0, idx].set_title(\"w/o aug\")\n","    axs[0, idx].axis('off')\n","    \n","    axs[1, idx].imshow(im_aug)\n","    axs[1, idx].set_title(\"aug\")\n","    axs[1, idx].axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#create training and validation sets\n","trainset = ConcatDataset([\n","    CustomTensorDataset(train_data, train_labels),\n","    CustomTensorDataset(train_data, train_labels, transform=transform)\n","])\n","valset = CustomTensorDataset(val_data, val_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#create dataloaders to make use of batching and shuffling\n","train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(valset, batch_size=32, shuffle=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#define the device to use\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"markdown","metadata":{},"source":["#### Define a basic ResNet18 building block. It differs a little from larger ResNet architectures, but the overall logic is the same. The block consist of two convolutional layers and supports skip connections."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-12-03T20:42:57.565890Z","iopub.status.busy":"2022-12-03T20:42:57.565559Z","iopub.status.idle":"2022-12-03T20:42:57.574037Z","shell.execute_reply":"2022-12-03T20:42:57.572768Z","shell.execute_reply.started":"2022-12-03T20:42:57.565859Z"},"trusted":true},"outputs":[],"source":["class Block(nn.Module):\n","    \n","    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n","        super(Block, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU()\n","        self.identity_downsample = identity_downsample\n","        \n","    def forward(self, x):\n","        identity = x\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        if self.identity_downsample is not None:\n","            identity = self.identity_downsample(identity)\n","        x += identity\n","        x = self.relu(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["#### Define ResNet18 architecture. It has some feature extraction at the beggining and four ResNet blocks with skip connections. At the end we use adaptive average pooling (for the model to be agnostic to the input image size) and a fully-connected layer"]},{"cell_type":"markdown","metadata":{},"source":["#### Identity dosnsampling is the way for skip connections to match the size of the main flow when it has been changed. It uses a convolutional layer to handle both, reducing width and height of the feature maps as well as increasing the number of channels. This approach adds a little more complexity to the model compared to the parameter-free identity mapping, but leads to slightly better results, according to the original paper"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-12-03T20:43:04.085788Z","iopub.status.busy":"2022-12-03T20:43:04.085471Z","iopub.status.idle":"2022-12-03T20:43:04.096881Z","shell.execute_reply":"2022-12-03T20:43:04.095983Z","shell.execute_reply.started":"2022-12-03T20:43:04.085757Z"},"trusted":true},"outputs":[],"source":["class ResNet_18(nn.Module):\n","    \n","    def __init__(self, image_channels, num_classes):\n","        \n","        super(ResNet_18, self).__init__()\n","        self.in_channels = 64\n","        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU()\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        \n","        #resnet layers\n","        self.layer1 = self.__make_layer(64, 64, stride=1)\n","        self.layer2 = self.__make_layer(64, 128, stride=2)\n","        self.layer3 = self.__make_layer(128, 256, stride=2)\n","        self.layer4 = self.__make_layer(256, 512, stride=2)\n","        \n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512, num_classes)\n","        \n","    def __make_layer(self, in_channels, out_channels, stride):\n","        \n","        identity_downsample = None\n","        if stride != 1:\n","            identity_downsample = self.identity_downsample(in_channels, out_channels)\n","            \n","        return nn.Sequential(\n","            Block(in_channels, out_channels, identity_downsample=identity_downsample, stride=stride), \n","            Block(out_channels, out_channels)\n","        )\n","        \n","    def forward(self, x):\n","        \n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        \n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","#         layer4 = x\n","\n","        \n","        x = self.avgpool(x)\n","#         avg = x\n","        x = x.view(x.shape[0], -1)\n","        x = self.fc(x)\n","#         return x, layer4, avg\n","        return x\n","    \n","    def identity_downsample(self, in_channels, out_channels):\n","        \n","        return nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1), \n","            nn.BatchNorm2d(out_channels)\n","        )"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-12-03T20:45:05.750008Z","iopub.status.busy":"2022-12-03T20:45:05.749697Z","iopub.status.idle":"2022-12-03T20:45:05.859215Z","shell.execute_reply":"2022-12-03T20:45:05.858251Z","shell.execute_reply.started":"2022-12-03T20:45:05.749976Z"},"trusted":true},"outputs":[],"source":["model = ResNet_18(3, 10)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-12-03T20:45:07.098534Z","iopub.status.busy":"2022-12-03T20:45:07.098213Z","iopub.status.idle":"2022-12-03T20:45:07.626374Z","shell.execute_reply":"2022-12-03T20:45:07.625287Z","shell.execute_reply.started":"2022-12-03T20:45:07.098504Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["output.size torch.Size([1, 10])\n","layer4.size torch.Size([1, 512, 16, 16])\n","avg.size torch.Size([1, 512, 1, 1])\n"]}],"source":["# input = torch.randn(1, 3, 512, 512)\n","# output, layer4, avg = model(input)\n","# print('output.size', output.size())\n","# print('layer4.size', layer4.size())\n","# print('avg.size', avg.size())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#count trainable parameters of the model\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","count_parameters(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#move the model to the device\n","model.to(device)\n","next(model.parameters()).is_cuda"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#define everything we need for training\n","epochs = 5\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n","lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=50, is_inception=False):\n","    \n","    since = time.time()\n","    val_acc_history = []\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        for phase in ['train', 'val']: # Each epoch has a training and validation phase\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            for inputs, labels in dataloaders[phase]: # Iterate over data\n","                \n","                inputs = transforms.functional.resize(inputs, (112, 112))\n","                inputs = inputs.to(device)\n","\n","                labels = labels.to(device)\n","\n","                optimizer.zero_grad() # Zero the parameter gradients\n","\n","                with torch.set_grad_enabled(phase == 'train'): # Forward. Track history if only in train\n","                    \n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, labels)\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    if phase == 'train': # Backward + optimize only if in training phase\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # Statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            \n","            if phase == 'val': # Adjust learning rate based on val loss\n","                lr_scheduler.step(epoch_loss)\n","                \n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","            if phase == 'val':\n","                val_acc_history.append(epoch_acc)\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model, val_acc_history"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model, _ = train_model(model, {\"train\": train_loader, \"val\": val_loader}, criterion, optimizer, epochs)"]},{"cell_type":"markdown","metadata":{},"source":["# Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#prepare test set for the model\n","test = test.values / 255\n","test = torch.from_numpy(test).view(test.shape[0], 1, 28, 28)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#prepare a dataloader with the test set\n","testset = CustomTensorDataset(test, None)\n","test_loader = DataLoader(testset, batch_size=32, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#turn on the evaluation mode and make predictions batch by batch (otherwise it lack gpu memory)\n","#to use predictions for the submission we first need to transfer to the cpu\n","model.eval()\n","labels = []\n","for inputs in test_loader:\n","    inputs = transforms.functional.resize(inputs, (112, 112))\n","    inputs = inputs.to(device)\n","    outputs = model(inputs)\n","    _, predictions = torch.max(outputs, 1)\n","    predictions = predictions.to(\"cpu\")\n","    labels.extend(predictions.numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission['Label'] = labels\n","submission.to_csv('submission.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.7.11 ('pytorch')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"vscode":{"interpreter":{"hash":"75f9afe369f05bbe02d2f29de4d0ebf9d06f61d6eee7f67e64b3ad4a9b976385"}}},"nbformat":4,"nbformat_minor":4}
